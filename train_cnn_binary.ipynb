{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code to force activate cpu... Comment to activate gpu\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paragd/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/paragd/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/paragd/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/paragd/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/paragd/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/paragd/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20646 images belonging to 2 classes.\n",
      "Found 2295 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"/mnt/DATA2/paragd/preproc/\"     # configure as required\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dir_path+\"train/\",\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size = (1024, 1024),\n",
    "    batch_size = 100,\n",
    "    class_mode = 'binary')\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    dir_path+\"validate/\",\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size = (1024, 1024),\n",
    "    batch_size = 10,\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 1022, 1022, 8)     80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 511, 511, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 509, 509, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 254, 254, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 252, 252, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 124, 124, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 768)               88474368  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               98432     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 88,671,169\n",
      "Trainable params: 88,671,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(8, (3,3), activation='relu', input_shape=(1024,1024,1)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Flatten(),\n",
    "#     keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(768, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parallel_model = multi_gpu_model(model, gpus=3) #configure as required\n",
    "parallel_model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = keras.optimizers.Adam(),\n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 184s 919ms/step - loss: 0.0493 - acc: 0.9804 - val_loss: 6.7401e-04 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 180s 901ms/step - loss: 0.0474 - acc: 0.9924 - val_loss: 4.1381e-05 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 172s 862ms/step - loss: 0.0071 - acc: 0.9990 - val_loss: 6.4445e-04 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 174s 869ms/step - loss: 0.0073 - acc: 0.9990 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 171s 857ms/step - loss: 0.0073 - acc: 0.9990 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 179s 897ms/step - loss: 0.0317 - acc: 0.9964 - val_loss: 2.4299e-04 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 174s 871ms/step - loss: 0.0067 - acc: 0.9989 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " 28/200 [===>..........................] - ETA: 2:43 - loss: 0.0017 - acc: 0.9996"
     ]
    }
   ],
   "source": [
    "history = parallel_model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=200,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=20,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.savefig('acc_small.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('loss_small.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}